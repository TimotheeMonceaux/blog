{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, sys, re\n",
    "from time import time\n",
    "import tqdm\n",
    "import numpy, pandas\n",
    "import sklearn.model_selection\n",
    "import matplotlib.pyplot as plt\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def timed(f):\n",
    "    \"\"\"A decorator that prints out the execution time of a function\"\"\"\n",
    "    def time_decorator(*args, **kwargs):\n",
    "        t = time()\n",
    "        res = f(*args, **kwargs)\n",
    "        print('Execution of \"{}()\": {:.2f}s'.format(f.__name__, time()-t))\n",
    "        return res\n",
    "    return time_decorator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE6240 Project 2:LSTMs for Language Detection\n",
    "## Timoth√©e Monceaux -  Robin Ricard - 04/24/2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<span style=\"color:darkblue\"><b><u>Note:</u></b> in this report, the instructions are in black while our notes/comments/answers are in darkblue. The code is also largely commented.</span><br><br>\n",
    "<h3 style=\"color:darkblue\">Important: This notebook is not exhaustive. Please read our [blog post](http://timothee.monceaux.me/blog/2017/04/24/lstm-for-language-detection.html) to consider our whole work for this project.</h3>\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTMs are useful for building character-sequential prediction models. In this project you will use it to build string scoring models which you will then combine into a single language detector.\n",
    "\n",
    "To begin, please refresh you background on LSTMs:\n",
    "\n",
    "* [http://colah.github.io/posts/2015-08-Understanding-LSTMs/](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
    "* [http://karpathy.github.io/2015/05/21/rnn-effectiveness/](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 -- Building String Scoring Models [100 points]\n",
    "* Download this dataset, [http://cloudmark.github.io/data/subset.zip](http://cloudmark.github.io/data/subset.zip) , which is used in this blog, [http://cloudmark.github.io/Language-Detection-Implemenation/](http://cloudmark.github.io/Language-Detection-Implemenation/) , for a language detection experiment. Note that the zip archive contains 23 files, each is the same text translated into a different language.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert(os.path.isfile('data/frn.txt'))\n",
    "assert(os.path.isfile('data/eng.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Review the Keras documentation and example on LSTM for text generation at [https://keras.io/getting-started/sequential-model-guide/](https://keras.io/getting-started/sequential-model-guide/) and [https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py](https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py). The example, in particular shows how to train an LSTM model. Note that we will not be using the sample generation part of the code (feel free to look at it, though)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For eng.txt and jap.txt, split each file into 80/20 learning/holdout subsets. Lowercase all of the letters for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Training Data: X = array of size (51510, 5, 47) & y = array of size (51510, 47)\n"
     ]
    }
   ],
   "source": [
    "class Dataset:\n",
    "    \"\"\"Read, Preprocess, and Split the Data\"\"\"\n",
    "    \n",
    "    def __init__(self, text='data/eng.txt', substr_size=5, standard_charset=True):\n",
    "        \"\"\"Initialize the object and preprocess the data\"\"\"\n",
    "        self.text = self.preprocess(open(text).read()) # the original text/corpus\n",
    "        self.substr_size = substr_size # the n from our n-grams\n",
    "        self.length = len(self.text)-self.substr_size-1 # the size of our complete dataset\n",
    "        \n",
    "        if standard_charset: # We use the default, hard-coded charset\n",
    "            chars = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', \\\n",
    "                    'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', \\\n",
    "                    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', \\\n",
    "                    ' ', '.', ',', ';', '\"', \"'\", '?', '!', '-', '_', ':']\n",
    "        else: # We build the charset from the input text\n",
    "            chars = sorted(list(set(self.text))) \n",
    "        self.n_chars = len(chars) # the number of different characters we're working with\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(chars)) # From a char, retrieves the corresponding index\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(chars)) # From an index, retrieves the corresponding char\n",
    "        \n",
    "        # We build our initials X and y\n",
    "        X = numpy.zeros((self.length, self.substr_size, self.n_chars), dtype=numpy.bool)\n",
    "        y = numpy.zeros((self.length, self.n_chars), dtype=numpy.bool)\n",
    "        for i in range(self.length):\n",
    "            for j in range(self.substr_size):\n",
    "                X[i, j, self.char_indices[self.text[i+j]]] = True\n",
    "            y[i, self.char_indices[self.text[i+self.substr_size]]] = True\n",
    "        X_train = X[:int(0.8*self.length),:,:]\n",
    "        self.X_test = X[int(0.8*self.length):,:,:]\n",
    "        y_train = y[:int(0.8*self.length),:]\n",
    "        self.y_test = y[int(0.8*self.length):,:]\n",
    "        \n",
    "        # We add all the padding alternatives to our training set\n",
    "        # Padded Alternatives: Example for n-gram \"TRUMP\": [\"xTRUM\", \"xxTRU\", \"xxxTR\", \"xxxxT\"]\n",
    "        self.X_train = numpy.array(X_train)\n",
    "        self.y_train = numpy.array(y_train)\n",
    "        for i in range(0, self.substr_size):\n",
    "            y_train = numpy.array(X_train[:, -1]) # In order always to predict the very next char\n",
    "            X_train[:, 1:] = X_train[:, :-1] # We swap every column to the left\n",
    "            X_train[:, 0] = False # A padded space is a char where all bools are false\n",
    "            self.X_train = numpy.concatenate([self.X_train, X_train], axis=0)\n",
    "            self.y_train = numpy.concatenate([self.y_train, y_train], axis=0)\n",
    "            \n",
    "    def preprocess(self, to_preprocess):\n",
    "        \"\"\"Convert all leters to lower and removes unwanted punctuation signs\"\"\"\n",
    "        res = to_preprocess.lower()\n",
    "        res = re.sub(r'[\\t\\n]', ' ', res)\n",
    "        res = re.sub(r'[^a-z+\\d+ \\.,;\"\\'\\?!\\-_:]', '', res)\n",
    "        return res\n",
    "    \n",
    "    def format(self, to_format):\n",
    "        \"\"\"Convert a string to a usable numpy array\"\"\"\n",
    "        to_format_ = self.preprocess(to_format)\n",
    "        res = numpy.zeros((len(to_format_), self.n_chars), dtype=numpy.bool)\n",
    "        for i in range(len(to_format_)):\n",
    "            res[i, self.char_indices[to_format_[i]]] = True\n",
    "        return res\n",
    "    \n",
    "    def unformat(self, to_unformat):\n",
    "        \"\"\"Convert a usable numpy array into the string it encodes\"\"\"\n",
    "        res = ''\n",
    "        for i in range(to_unformat.shape[0]):\n",
    "            res += self.indices_char[numpy.argmax(to_unformat[i])]\n",
    "        return res\n",
    "    \n",
    "    def sample(self, size=100):\n",
    "        indices = numpy.random.choice(numpy.arange(self.X_test.shape[0]), size)\n",
    "        return (self.X_test[indices], self.y_test[indices])\n",
    "\n",
    "english = Dataset()\n",
    "french = Dataset(\"data/frn.txt\")\n",
    "print(\"Generated Training Data: X = array of size {} & y = array of size {}\".format(english.X_train.shape, english.y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Train two LSTM models (size 128), one for eng.txt and one for jap.txt, on the learning datasets you created. Set nepochs=5. You can experiment with other settings if you like. An example line from your script might be: model.fit(X_train_eng, y_train_eng, batch_size=128, nb_epoch=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128)               90112     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 47)                6063      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 47)                0         \n",
      "=================================================================\n",
      "Total params: 96,175.0\n",
      "Trainable params: 96,175.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "51510/51510 [==============================] - 6s - loss: 2.2843     \n",
      "Epoch 2/5\n",
      "51510/51510 [==============================] - 5s - loss: 1.9310     \n",
      "Epoch 3/5\n",
      "51510/51510 [==============================] - 5s - loss: 1.7917     \n",
      "Epoch 4/5\n",
      "51510/51510 [==============================] - 5s - loss: 1.7110     \n",
      "Epoch 5/5\n",
      "51510/51510 [==============================] - 5s - loss: 1.6591     \n",
      "\n",
      "Generated from the seed \"ment \":\n",
      "ment the right to law imsoms and the right to securither limitand assespand and reticled to social care rights of this consclediage his communibjrone has the right to equal protection and the hight to security everyone has the communibjeceedo securithing, social care and nociremente may including of the right to the himsell-befor himself and and in the rights and egard and to limitand all chright \n"
     ]
    }
   ],
   "source": [
    "class LSTM:\n",
    "    \"\"\"A LSTM model that is used to predict the language of a given sentence\"\"\"\n",
    "    \n",
    "    def __init__(self, dataset, verbose=False):\n",
    "        \"\"\"Initialize the object and compile the model\"\"\"\n",
    "        self.dataset = dataset\n",
    "        self.model = keras.models.Sequential()\n",
    "        self.model.add(keras.layers.LSTM(128, input_shape=(self.dataset.substr_size, self.dataset.n_chars)))\n",
    "        self.model.add(keras.layers.Dense(self.dataset.n_chars))\n",
    "        self.model.add(keras.layers.Activation('softmax'))\n",
    "        optimizer = keras.optimizers.RMSprop(lr=0.01)\n",
    "        self.model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "        if verbose:\n",
    "            self.model.summary()\n",
    "            \n",
    "    def train(self, epochs=5, verbose=False):\n",
    "        \"\"\"Train the model on the dataset's training set\"\"\"\n",
    "        if verbose: # prints generated text at each epoch for several temperatures (importance of randomness when choosing the next char)\n",
    "            for i in range(epochs):\n",
    "                self.model.fit(self.dataset.X_train, self.dataset.y_train, batch_size=128, epochs=1, shuffle=False)\n",
    "                for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
    "                    print()\n",
    "                    print(\"For temperature {}:\".format(temperature))\n",
    "                    self.generate(temperature=temperature)\n",
    "                print()\n",
    "        else: # We're not prompting anything else than the advancement\n",
    "            self.model.fit(self.dataset.X_train, self.dataset.y_train, batch_size=128, epochs=epochs, shuffle=False)\n",
    "        return self\n",
    "    \n",
    "    def generate(self, seed=None, size=400, temperature=0.5):\n",
    "        \"\"\"Given some seed (string), generate a text of size size\"\"\"\n",
    "        def sample(preds):\n",
    "            \"\"\"Sample an index from a probability array\"\"\"\n",
    "            preds = numpy.asarray(preds).astype('float64')\n",
    "            preds = numpy.log(preds) / temperature\n",
    "            exp_preds = numpy.exp(preds)\n",
    "            preds = exp_preds / numpy.sum(exp_preds)\n",
    "            probas = numpy.random.multinomial(1, preds, 1)\n",
    "            return numpy.argmax(probas)\n",
    "        \n",
    "        # By default, we use some random string from the original text as a seed\n",
    "        if not seed:\n",
    "            starting_point = numpy.random.randint(0, len(self.dataset.text)-self.dataset.substr_size)\n",
    "            seed = self.dataset.text[starting_point: starting_point + self.dataset.substr_size]\n",
    "        print('\\nGenerated from the seed \"{}\":'.format(seed))\n",
    "        generated = seed\n",
    "        sys.stdout.write(seed)\n",
    "        for _ in range(len(seed), size):\n",
    "            # We predict the next character after the end of our generated string\n",
    "            preds = self.model.predict(numpy.array([self.dataset.format(generated[-self.dataset.substr_size:])]))[0]\n",
    "            ix = sample(preds)\n",
    "            char = self.dataset.indices_char[ix]\n",
    "            # We append the generated character to the end of our string and prompt it\n",
    "            generated += char\n",
    "            sys.stdout.write(char)\n",
    "        print()\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X_test=None):\n",
    "        \"\"\"Given a matrix X_test of preprocessed n-grams, returns a estimated probability\n",
    "        of each n-grams belonging to the same language as our training set\"\"\"\n",
    "        # By default, we're working on copies of our dataset's testing set\n",
    "        if X_test == None:\n",
    "            X_test = self.dataset.X_test\n",
    "        X_test = numpy.array(X_test)\n",
    "            \n",
    "        # Several assertions on X_test \n",
    "        if X_test.shape[2]!=self.dataset.n_chars:\n",
    "            raise ValueError(\"X must be working on the same charset as used dataset\")\n",
    "        if X_test.shape[1]!=self.dataset.substr_size:\n",
    "            raise ValueError(\"X must be constituted of {}-grams (here {}-grams)\".format(self.dataset.substr_size, X_test.shape[1]))\n",
    "        \n",
    "        # res will contain the probabilities of a n-grams and its padded alternatives belonging to the language\n",
    "        # Padded Alternatives: Example for n-gram \"TRUMP\": [\"xTRUM\", \"xxTRU\", \"xxxTR\", \"xxxxT\", \"xxxxx\"]\n",
    "        res = numpy.zeros((X_test.shape[0], self.dataset.substr_size)) # Order of the columns: [\"xxxxx\", \"xxxxT\", \"xxxTR\", \"xxTRU\", \"xTRUM\"]   \n",
    "        for i in range(self.dataset.substr_size):\n",
    "            y_test = numpy.array(X_test[:, -1]) # In order always to predict the very next char\n",
    "            X_test[:, 1:] = X_test[:, :-1] # We swap every column to the left\n",
    "            X_test[:, 0] = False # A padded space is a char where all bools are false\n",
    "            res[:, self.dataset.substr_size-i-1] = self.model.predict(X_test)[y_test] # We only want the prob on the next char\n",
    "        return numpy.sum(numpy.log(res), axis=1) # we return the overall log-likelyhood\n",
    "            \n",
    "english_lstm = LSTM(Dataset(), verbose=True).train().generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 128)               90112     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 47)                6063      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 47)                0         \n",
      "=================================================================\n",
      "Total params: 96,175.0\n",
      "Trainable params: 96,175.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "57570/57570 [==============================] - 6s - loss: 2.2037     \n",
      "Epoch 2/5\n",
      "57570/57570 [==============================] - 5s - loss: 1.9034     \n",
      "Epoch 3/5\n",
      "57570/57570 [==============================] - 5s - loss: 1.7871     \n",
      "Epoch 4/5\n",
      "57570/57570 [==============================] - 6s - loss: 1.7216     \n",
      "Epoch 5/5\n",
      "57570/57570 [==============================] - 5s - loss: 1.6794     \n",
      "\n",
      "Generated from the seed \"4 tou\":\n",
      "4 tout conte a droit a une a droits fondace ses de sa a droit a une existance de sa defen tant a une a droits de sa republicat de sa per une personne a une l'homme a une a droit a une de sa de personne a une a droit de fonder a une a droit a une personne a droit a une a droit a une a de melle. 2. toute perioder sa de personne a droit a un soute perte et a un a une a droits et et a une independamen\n"
     ]
    }
   ],
   "source": [
    "french_lstm = LSTM(Dataset(\"data/frn.txt\"), verbose=True).train().generate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:darkblue\">As we can tell from both these outputs, the text generation from these LSTMs is pretty good. Even though the text generated doesn't mean much, it follows the overall structure and characters represention of English and French languages. The generated texts could be used as <i>Lorem Ipsum</i> for instance</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Generate a test dataset from the holdout files. From each of eng_holdout.txt and jap_holdout.txt files, randomly select 100 5-char substrings. You will end up with 200 test strings. These are the x_test for evaluation. The y_test are 1 for english and 0 for japanese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout data created: X_holdout of size (200, 5, 47) and y_holdout of size (200,).\n"
     ]
    }
   ],
   "source": [
    "class LanguageDiscriminator:\n",
    "    \"\"\"Combines two LSTM to distinguish some input from the different languages\"\"\"\n",
    "    \n",
    "    def __init__(self, lstm1, lstm2, language1=\"English\", language2=\"French\"):\n",
    "        \"\"\"Assert that the two provided LSTMs can work together and initialize the discriminator\"\"\"\n",
    "        if lstm1.dataset.n_chars != lstm2.dataset.n_chars:\n",
    "            raise ValueError(\"Both lstm/datasets must work on the same charset\")\n",
    "        if lstm1.dataset.substr_size != lstm2.dataset.substr_size:\n",
    "            raise ValueError(\"Both lstm/datasets must work on the same substring size\")\n",
    "        self.lstm1 = lstm1\n",
    "        self.dataset1 = self.lstm1.dataset\n",
    "        self.language1 = language1\n",
    "        self.lstm2 = lstm2\n",
    "        self.dataset2 = self.lstm2.dataset\n",
    "        self.language2 = language2\n",
    "        \n",
    "    def generate_sample_test_data(self, n=100, shuffle=True):\n",
    "        \"\"\"Generate a merged dataset from two samples of size n from the two different datasets\"\"\"\n",
    "        x1, _ = self.dataset1.sample(n)\n",
    "        y1 = [0] * x1.shape[0]\n",
    "        x2, _ = self.dataset2.sample(n)\n",
    "        y2 = [1] * x1.shape[0]\n",
    "        x = numpy.concatenate([x1, x2])\n",
    "        y = numpy.concatenate([y1, y2])\n",
    "        if shuffle:\n",
    "            x, _, y, _ = sklearn.model_selection.train_test_split(x, y, test_size=0)\n",
    "        return (x, y)\n",
    "    \n",
    "    def predict_probas(self, X=None):\n",
    "        \"\"\"Return both languages log-likelyhood for each row of X\"\"\"\n",
    "        if X==None:\n",
    "            X, _ = self.generate_sample_test_data()\n",
    "        res = numpy.empty((X.shape[0], 2))\n",
    "        res[:,0] = self.lstm1.predict(X)\n",
    "        res[:,1] = self.lstm2.predict(X)\n",
    "        return res\n",
    "    \n",
    "    def predict(self, X=None):\n",
    "        \"\"\"Return predicted labels for each row of X\"\"\"\n",
    "        if X==None:\n",
    "            X, _ = self.generate_sample_test_data()\n",
    "        preds = self.predict_probas(X)\n",
    "        return numpy.argmax(preds, axis=1)\n",
    "    \n",
    "    def score(self, X=None, y=None):\n",
    "        \"\"\"Output the accuracy on the classifier over X and y\"\"\"\n",
    "        if X==None and y==None:\n",
    "            X, y = self.generate_sample_test_data()\n",
    "            \n",
    "        # Several assertions on X and y\n",
    "        if X.shape[0]!=y.shape[0]:\n",
    "            raise ValueError(\"X and y must be of the same size\")\n",
    "        if X.shape[1]!=self.dataset1.substr_size:\n",
    "            raise ValueError(\"X must be constituted of {}-grams (here {}-grams)\".format(self.dataset1.substr_size, X.shape[1]))\n",
    "            \n",
    "        preds = self.predict(X)\n",
    "        return 1-numpy.abs(preds-y).sum()/X.shape[0]\n",
    "    \n",
    "    def plot_roc_curve(self, X=None, y=None):\n",
    "        \"\"\"Plot the Receiver Operating Characteristic curve for the current model\"\"\"\n",
    "        if X==None and y==None:\n",
    "            X, y = self.generate_sample_test_data()\n",
    "            \n",
    "        # Several assertions on X and y\n",
    "        if X.shape[0]!=y.shape[0]:\n",
    "            raise ValueError(\"X and y must be of the same size\")\n",
    "        if X.shape[1]!=self.dataset1.substr_size:\n",
    "            raise ValueError(\"X must be constituted of {}-grams (here {}-grams)\".format(self.dataset1.substr_size, X.shape[1]))\n",
    "        \n",
    "        # We build y_hat as the ratio between both class loglikelyhood\n",
    "        preds = self.predict_probas(X)\n",
    "        y_hat = preds[:,1] - preds[:, 0]\n",
    "        \n",
    "        # We compute the ROC & AUC for our predictions\n",
    "        fpr, tpr, _ = sklearn.metrics.roc_curve(y, y_hat)\n",
    "        roc_auc = sklearn.metrics.auc(fpr, tpr)\n",
    "        \n",
    "        # We build and display the plot using matplotlib\n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr, color='darkorange',\n",
    "                 lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver Operating Characteristic on our Language Classifier')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "        return roc_auc\n",
    "\n",
    "X_holdout, y_holdout = LanguageDiscriminator(english_lstm, french_lstm).generate_sample_test_data()\n",
    "print(\"Holdout data created: X_holdout of size {} and y_holdout of size {}.\".format(X_holdout.shape, y_holdout.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * For each test string, compute the log likelihood of that string for each model. This is the hard part of the assignment and may require a little bit of thought, but you use model.predict() and conceptually generate the predicted probability for each string. For example, if my test_string is ‚Äútrump‚Äù you would use model.predict() to compute Pr(t|START), Pr(r|START,t), Pr(u|START,tr), ‚Ä¶ Pr(p|STARTtrum), take the log of the probabilities and add them up. So for each test string you will end up with two numbers (log(Pr(string|eng)), log(Pr(string|jap)))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Timothee\\Anaconda3\\envs\\DeepLearning\\lib\\site-packages\\ipykernel\\__main__.py:40: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "C:\\Users\\Timothee\\Anaconda3\\envs\\DeepLearning\\lib\\site-packages\\ipykernel\\__main__.py:31: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "C:\\Users\\Timothee\\Anaconda3\\envs\\DeepLearning\\lib\\site-packages\\ipykernel\\__main__.py:63: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy on 10 tries of our Language Discriminator following this model: 0.8200.\n"
     ]
    }
   ],
   "source": [
    "ld = LanguageDiscriminator(english_lstm, french_lstm)\n",
    "avg_accuracy = 0\n",
    "for _ in range(10):\n",
    "    avg_accuracy += ld.score()\n",
    "print(\"Average accuracy on 10 tries of our Language Discriminator following this model: {:.4f}.\".format(avg_accuracy/10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * Use standard sklearn to compute an ROC where y_hat is the ratio of the two loglikelihood ratios. For example, if ‚Äútrump‚Äù -> (0.8, 0.4), your y_hat would be 0.8/0.4 = 2\n",
    " * Plot the ROC on semilogx and print the AUC-ROC on the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Timothee\\Anaconda3\\envs\\DeepLearning\\lib\\site-packages\\ipykernel\\__main__.py:31: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "C:\\Users\\Timothee\\Anaconda3\\envs\\DeepLearning\\lib\\site-packages\\ipykernel\\__main__.py:63: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEWCAYAAACjYXoKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNQeO1NGyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19576bb69b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC ROC for the plot: 0.92\n"
     ]
    }
   ],
   "source": [
    "auc_roc = LanguageDiscriminator(english_lstm, french_lstm).plot_roc_curve()\n",
    "print(\"AUC ROC for the plot: {:.2f}\".format(auc_roc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Is this model good?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:darkblue\">Yes, this model is really good: it shows an average accuracy of <b>0.82</b> and an AUC-ROC of <b>0.92</b>. There is still room for improvements but it shows that both LSTM models have understood the underlying structure of languages they're working on.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What are at least three alternatives to language detection that you can think of or find on the internet? What are the pros and cons of each approach?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:darkblue\">\n",
    "<ul>\n",
    "<li>N-grams</li>\n",
    "<li>Term Frequency</li>\n",
    "<li>Mutual Information</li>\n",
    "</ul>\n",
    "Please read our [blog post](http://timothee.monceaux.me/blog/2017/04/24/lstm-for-language-detection.html) for more explanations about these methods\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Briefly describe at least 5 ways that you can improve this model, and what you think the value and predicted result of each approach would be? Example: ‚Äúcould use GPUs for training -> faster to get datasets; no change in efficacy‚Äù\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:darkblue\">\n",
    "<ul>\n",
    "<li>Tune the LSTM -> change hyperparameters to improve the results</li>\n",
    "<li>Increase the corpus size -> more training, better results</li>\n",
    "<li>Changing the charset -> get the model more focused on what really matters</li>\n",
    "<li>Form of bagging where a same language would get multiple LSTM nets -> Increase accuracy</li>\n",
    "<li>Mix LSTM layers with anything else than a dense layer -> More complete model, better results</li>\n",
    "</ul>\n",
    "Please read our [blog post](http://timothee.monceaux.me/blog/2017/04/24/lstm-for-language-detection.html) for more explanations about these methods\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 -- Extra Credit [up to 40 points]\n",
    "For extra credit you should explore improvements to the language detection experiment. You are free to choose, and the amount of extra credit will be subjectively assigned based on how complete, interesting and effective the approach is at improving the experiment. Note that you don‚Äôt have to necessarily improve your detector results; some baseline experiments that might be expected to perform poorly may still be valuable for educational purposes.\n",
    "\n",
    "Some examples:\n",
    "* Train models for all languages. How do you score, then?\n",
    "* Explore early stopping by monitoring the validation dataset fit.\n",
    "* Explore variations in the hyperparameters of the model, including the size and number of LSTM layers.\n",
    "* Compare to simpler methods like n-grams or hmms or others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training models for all languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dns</th>\n",
       "      <th>dut</th>\n",
       "      <th>eng</th>\n",
       "      <th>frn</th>\n",
       "      <th>ger</th>\n",
       "      <th>hng</th>\n",
       "      <th>itn</th>\n",
       "      <th>ltn</th>\n",
       "      <th>ltn1</th>\n",
       "      <th>lux</th>\n",
       "      <th>mls</th>\n",
       "      <th>por</th>\n",
       "      <th>rum</th>\n",
       "      <th>spn</th>\n",
       "      <th>yps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dns</th>\n",
       "      <td>-</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dut</th>\n",
       "      <td>0.845</td>\n",
       "      <td>-</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eng</th>\n",
       "      <td>0.845</td>\n",
       "      <td>0.89</td>\n",
       "      <td>-</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frn</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.835</td>\n",
       "      <td>-</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ger</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.885</td>\n",
       "      <td>-</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hng</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.93</td>\n",
       "      <td>-</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>itn</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>-</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ltn</th>\n",
       "      <td>0.915</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.89</td>\n",
       "      <td>-</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ltn1</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.63</td>\n",
       "      <td>-</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lux</th>\n",
       "      <td>0.885</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.92</td>\n",
       "      <td>-</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mls</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.925</td>\n",
       "      <td>-</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>por</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.925</td>\n",
       "      <td>-</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rum</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.83</td>\n",
       "      <td>-</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spn</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.855</td>\n",
       "      <td>-</td>\n",
       "      <td>0.955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yps</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.955</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        dns    dut    eng    frn    ger    hng    itn    ltn   ltn1    lux  \\\n",
       "dns       -  0.845  0.845  0.865   0.85   0.93   0.92  0.915   0.94  0.885   \n",
       "dut   0.845      -   0.89   0.91  0.845  0.875   0.91  0.935   0.92  0.865   \n",
       "eng   0.845   0.89      -  0.835  0.855  0.955   0.88   0.86   0.84  0.885   \n",
       "frn   0.865   0.91  0.835      -  0.885  0.965   0.81   0.83   0.82  0.895   \n",
       "ger    0.85  0.845  0.855  0.885      -   0.93   0.94  0.935   0.92  0.825   \n",
       "hng    0.93  0.875  0.955  0.965   0.93      -   0.96  0.935  0.955   0.92   \n",
       "itn    0.92   0.91   0.88   0.81   0.94   0.96      -   0.89  0.865  0.925   \n",
       "ltn   0.915  0.935   0.86   0.83  0.935  0.935   0.89      -   0.63  0.905   \n",
       "ltn1   0.94   0.92   0.84   0.82   0.92  0.955  0.865   0.63      -   0.92   \n",
       "lux   0.885  0.865  0.885  0.895  0.825   0.92  0.925  0.905   0.92      -   \n",
       "mls    0.95  0.935   0.96  0.935   0.95   0.94   0.91  0.945   0.94  0.925   \n",
       "por    0.92   0.94  0.865   0.85   0.94  0.945  0.795  0.815  0.855   0.89   \n",
       "rum    0.93   0.95   0.88   0.85  0.925   0.97  0.875  0.825  0.835  0.905   \n",
       "spn    0.93   0.91   0.83  0.795   0.94   0.95   0.87   0.88  0.875   0.93   \n",
       "yps    0.92   0.94  0.965   0.97  0.945   0.95  0.955  0.945   0.95  0.955   \n",
       "\n",
       "        mls    por    rum    spn    yps  \n",
       "dns    0.95   0.92   0.93   0.93   0.92  \n",
       "dut   0.935   0.94   0.95   0.91   0.94  \n",
       "eng    0.96  0.865   0.88   0.83  0.965  \n",
       "frn   0.935   0.85   0.85  0.795   0.97  \n",
       "ger    0.95   0.94  0.925   0.94  0.945  \n",
       "hng    0.94  0.945   0.97   0.95   0.95  \n",
       "itn    0.91  0.795  0.875   0.87  0.955  \n",
       "ltn   0.945  0.815  0.825   0.88  0.945  \n",
       "ltn1   0.94  0.855  0.835  0.875   0.95  \n",
       "lux   0.925   0.89  0.905   0.93  0.955  \n",
       "mls       -  0.925   0.91  0.915  0.915  \n",
       "por   0.925      -   0.83  0.715   0.97  \n",
       "rum    0.91   0.83      -  0.855   0.95  \n",
       "spn   0.915  0.715  0.855      -  0.955  \n",
       "yps   0.915   0.97   0.95  0.955      -  "
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "# removed czc, grk, jpn, lat, lit, rmn1, rus, ukr for they have characters unrecognized by python\n",
    "# making an actual classifier would be pretty easy based on this\n",
    "languages = ['dns', 'dut', 'eng', 'frn', 'ger', 'hng', \\\n",
    "             'itn', 'ltn', 'ltn1', 'lux', 'mls', \\\n",
    "             'por', 'rum', 'spn', 'yps']\n",
    "\n",
    "res_languages = pandas.DataFrame('-', index=languages, columns=languages)\n",
    "for lang1, lang2 in itertools.combinations(languages, 2): # for all combinations of languages\n",
    "    print(lang1, lang2) # we prompt the advancement of the computation\n",
    "    res_languages.ix[lang1][lang2] = LanguageDiscriminator(LSTM(Dataset(\"data/\"+lang1+\".txt\")).train(), LSTM(Dataset(\"data/\"+lang2+\".txt\")).train()).score()\n",
    "    res_languages.ix[lang2][lang1] = res_languages.ix[lang1][lang2] # the matrix is symetric\n",
    "    clear_output()\n",
    "\n",
    "res_languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:darkblue\">As we can tell from these results, our model is pretty consistent with the all tested languages, with the exception or <i>ltn vs. ltn1</i>, for these languages are extremely close together. Our best results are <i>yps vs frn</i> and <i>yps vs por</i> with an accuracy of <b>0.97</b>, which is an excellent score.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring variations of Hyperparamters\n",
    "<div style=\"color:darkblue\"><br>\n",
    "For this part, we studied the influence of the following hyperparameters:\n",
    "<ul><li><b>Size of the substring (default 5):</b></li></ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.66</td>\n",
       "      <td>44.8667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.745</td>\n",
       "      <td>56.6141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.8</td>\n",
       "      <td>89.146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.9</td>\n",
       "      <td>206.376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.985</td>\n",
       "      <td>392.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.965</td>\n",
       "      <td>599.342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>1284.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1</td>\n",
       "      <td>2022.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.62</td>\n",
       "      <td>3049.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy     Time\n",
       "2      0.66  44.8667\n",
       "3     0.745  56.6141\n",
       "5       0.8   89.146\n",
       "10      0.9  206.376\n",
       "15    0.985   392.82\n",
       "20    0.965  599.342\n",
       "30        1  1284.11\n",
       "40        1  2022.78\n",
       "50     0.62   3049.9"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_test = [2, 3, 5, 10, 15, 20, 30, 40, 50]\n",
    "res_substr_size = pandas.DataFrame(columns=[\"Accuracy\", \"Time\"], index=to_test)\n",
    "for size_of_the_substring in to_test:\n",
    "    t = time()\n",
    "    print(\"size_of_the_substring: \",size_of_the_substring)\n",
    "    res_substr_size.ix[size_of_the_substring][\"Accuracy\"] = LanguageDiscriminator(LSTM(Dataset(substr_size=size_of_the_substring)).train(), LSTM(Dataset(\"data/frn.txt\", substr_size=size_of_the_substring)).train()).score()\n",
    "    res_substr_size.ix[size_of_the_substring][\"Time\"] = time()-t\n",
    "    clear_output()\n",
    "res_substr_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:darkblue\">As we can tell from the output above, the size of the substring has a <b>great influence</b> over the the accuracy and computational time. It grows continuously until 40, and at that point it starts to <b>overfit</b> and decrease rapidly to a point at which it's only slightly better than chance.\n",
    "<br><br>\n",
    "<i><u>Note:</u> At substring size of 30 and 40, the computed accuracy is 1. That doesn't mean that the actual accuracy of our model is 100%. Indeed, as we only tested it on 200 samples, and it got every single one of them right, that means that <b>the accuracy of our model is >0.995</b></i><br><br>\n",
    "<i><u>Note:</u> The size of the substring isn't the only influential parameter in this experience, as it also has a side effect. Indeed, as we are also training on every padded version of each substring, increasing their size will also increase the size of the training set. This partly explains the better results, but also the longer computational time.</i></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:darkblue\"><ul><li><b>Number of training epochs (default 5):</b></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8</td>\n",
       "      <td>46.6343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.785</td>\n",
       "      <td>59.4425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.815</td>\n",
       "      <td>85.4587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.8</td>\n",
       "      <td>147.736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.84</td>\n",
       "      <td>210.961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.85</td>\n",
       "      <td>276.881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.795</td>\n",
       "      <td>403.249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.79</td>\n",
       "      <td>524.788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.785</td>\n",
       "      <td>647.926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy     Time\n",
       "2       0.8  46.6343\n",
       "3     0.785  59.4425\n",
       "5     0.815  85.4587\n",
       "10      0.8  147.736\n",
       "15     0.84  210.961\n",
       "20     0.85  276.881\n",
       "30    0.795  403.249\n",
       "40     0.79  524.788\n",
       "50    0.785  647.926"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_test = [2, 3, 5, 10, 15, 20, 30, 40, 50]\n",
    "res_n_epochs = pandas.DataFrame(columns=[\"Accuracy\", \"Time\"], index=to_test)\n",
    "for n_epochs in to_test:\n",
    "    t = time()\n",
    "    print(\"n_epochs: \",n_epochs)\n",
    "    res_n_epochs.ix[n_epochs][\"Accuracy\"] = LanguageDiscriminator(LSTM(Dataset()).train(epochs=n_epochs), LSTM(Dataset(\"data/frn.txt\")).train(epochs=n_epochs)).score()\n",
    "    res_n_epochs.ix[n_epochs][\"Time\"] = time()-t\n",
    "    clear_output()\n",
    "res_n_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:darkblue\">As we can tell from the output above, the number of training epochs doesn't have much influence over the accuracy of our model. The accuracy seems to gradually, slowly increase intil about 20 epochs, where it starts to <b>overfit</b> and fall back. The computational time increases linearly to the number of training epochs, which is kind of intuitive.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:darkblue\"><ul><li><b>Set of character used (default r'[a-z+\\d+ \\\\.,;\"'?!-_:]'):</b></li></ul><br>\n",
    "For this part, we computed four different versions of both <i>eng.txt</i> and <i>frn.txt</i> to the following different sets of characters:\n",
    "<ul>\n",
    "<li><i>everything:</i> default version</li>\n",
    "<li><i>no_punctuation:</i> keep only letters, numbers and spaces</li>\n",
    "<li><i>no_punctuation_digits:</i> keep only letters and spaces</li>\n",
    "<li><i>no_punctuation_digits_spaces:</i> keep only letters</li>\n",
    "</ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>everything</th>\n",
       "      <td>0.84</td>\n",
       "      <td>107.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_punctuation</th>\n",
       "      <td>0.785</td>\n",
       "      <td>109.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_punctuation_digits</th>\n",
       "      <td>0.815</td>\n",
       "      <td>103.357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_punctuation_digits_spaces</th>\n",
       "      <td>0.815</td>\n",
       "      <td>92.1093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Accuracy     Time\n",
       "everything                       0.84  107.585\n",
       "no_punctuation                  0.785  109.083\n",
       "no_punctuation_digits           0.815  103.357\n",
       "no_punctuation_digits_spaces    0.815  92.1093"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_test = [\"no_punctuation\", \"no_punctuation_digits\", \"no_punctuation_digits_spaces\"]\n",
    "res_charset = pandas.DataFrame(columns=[\"Accuracy\", \"Time\"], index=[\"everything\"]+to_test)\n",
    "t = time()\n",
    "res_charset.ix[\"everything\"][\"Accuracy\"] = LanguageDiscriminator(LSTM(Dataset()).train(), LSTM(Dataset(\"data/frn.txt\")).train()).score()\n",
    "res_charset.ix[\"everything\"][\"Time\"] = time()-t\n",
    "for charset in to_test:\n",
    "    t = time()\n",
    "    print(\"charset: \", charset)\n",
    "    res_charset.ix[charset][\"Accuracy\"] = LanguageDiscriminator(LSTM(Dataset(\"data/eng_\"+charset+\".txt\")).train(), LSTM(Dataset(\"data/frn_\"+charset+\".txt\")).train()).score()\n",
    "    res_charset.ix[charset][\"Time\"] = time()-t\n",
    "    clear_output()\n",
    "res_charset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:darkblue\">As we can tell from the output above, the set of characters used has very little influence over the accuracy of our model. The best score is still when the charset used is the default one, the one with everything. We can guess that punctuation and spaces help captures the internal structure of English and French languages.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the model to other texts\n",
    "<div style=\"color:darkblue\">\n",
    "For this part, we tried training our LSTM models on different datasets and different types of texts to see what quality of content it could generate. We trained our model on the following datasets:<br>\n",
    "<ul><li><b>Wikipedia Articles (random paragraphs from random wikipedia articles):</b></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "95328/95328 [==============================] - 87s - loss: 2.1606    \n",
      "Epoch 2/5\n",
      "95328/95328 [==============================] - 53s - loss: 1.3820    \n",
      "Epoch 3/5\n",
      "95328/95328 [==============================] - 51s - loss: 1.0714    \n",
      "Epoch 4/5\n",
      "95328/95328 [==============================] - 47s - loss: 0.9413    \n",
      "Epoch 5/5\n",
      "95328/95328 [==============================] - 48s - loss: 0.8651    \n",
      "\n",
      "Generated from the seed \" by the revenge\":\n",
      " by the revenge ason was mostook to producers of the brong, knownine nerds aired corralio and he was hor the say affece comby, thetrated held the contucky of the season wassond securly frouge or new york ciedt as ans\" he was arred only badully undwa ibborst. tan is sid layonksord it aumod only culs assoce relth so audy to produce only spy: currdard th stealicathedrapic eali is added the trogen, sometor instruments well-squestrume hed with the roon, boham also abson was hosted by actord diocetract to the trace a or bellionsity subwly sul, in prosecuted by actor. been assock ents were the claimed equly, who harred as whlte only bulle, to the concentrated with numerons the season waskd was as of tasond cursit brenseason the context of talkinerd univg overheared by adialso are fay, who hadlamorrs assocropt, the frodure was hor the the the to the trace a brain her producers asold's aikleinhabeasinerds aireclace affect the cerradinerait holk times exommoce a braltor of styel position he hod. the dolfie whelh what as anbocutrator to 145th seallem, and asofte say whather diose cortucky. orcen the context of talkineresce bears. films, the season waskored the crommons's organssial sich the claim, as march the cessed he bast voss acaithor of steam-powered by actor in the context of taskolkion as the revenge of the held there lewher by acconconstructer, as worl pantory again to the the containm, and asothe cated of styely assue ronx, as whelle to say how manainbonseed as well as well asstrow earin the context of tarket. lineralsid season to the concoursed oodkir rolt .ies the revenge of tas held thered held there when somethe soil arvanched positions, baskolsition he had been assock enty councu, the crime som, either position he had been pastor the croof plantations whether dioce and busiss\" to idstat the trace a brain herb producitly say whan are choucke moder's carradibere cert carrst. plannotad been pastor the crantily fully undergrauchydither to issock to stee revenge asof the season waskored the croonx, as whell when they was whele centurriated the croof the season waskored the concoursed tyorl mactor so frodures from a bears. films, the season hos,ed by ine of bridgepor he crimes or morrs corrams. hertiolemdyach the soil or negataineroundiclained beer diock and asont. he reali reles ass, and esapm, and asort carradileto it is the cerrast to use a fully, knownd builtine age anost say how car'st, there assock entuclasond tooger\" darwoanic xalicnellicle assueereinh\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.LSTM at 0x14aacab3eb8>"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM(Dataset(\"data/wiki.txt\", substr_size=15)).train().generate(size=2500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:darkblue\">We can see from the output above that the results are note as good as what we could expect. This may be due to the fact that Wikipedia articles tells about a wide variety of subjects with a lot a really specific/technical words and names, thus quickly become over-complicated for our model. We should try on a text with a much smaller vocabulary.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:darkblue\"><ul><li><b>Novel extracts (random paragraphs from Jack London - Martin Eden):</b></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "215680/215680 [==============================] - 144s - loss: 1.8368   \n",
      "Epoch 2/5\n",
      "215680/215680 [==============================] - 115s - loss: 1.3656   \n",
      "Epoch 3/5\n",
      "215680/215680 [==============================] - 115s - loss: 1.1838   \n",
      "Epoch 4/5\n",
      "215680/215680 [==============================] - 115s - loss: 1.0895   \n",
      "Epoch 5/5\n",
      "215680/215680 [==============================] - 117s - loss: 1.0296   \n",
      "\n",
      "Generated from the seed \"n she had taken\":\n",
      "n she had taken the was no so far nearer, talking nearybeahing come than the world, and to the fast looking of soul out lefior to feie caced ly of eyes ff orld so lave gyinssinuthe mean worked the poare, anot him, like fee scove a scarions and was was a nurry. pointent of anothe so faist oper dient and form him and the two fight-fly he the old of broak, ruth. he so faint o blact morie wee no so fal coass in the time and she would no make sudeasing so making worlh-ly in thand to the fieriepsoon on toly, lone of soul ,umm noworked with his towering promping inter and he love that he so faiet indle and the tent for him, confident of rekecl oped him, cient so fad nowerain wele so far witces, rekfult of his mike to degrience, with open the was consing in the was never singere of he begeninations; butched with enced love that he for a the fident of eyes fece to so fal him of rew hom, as in him and student of powar, but no spirity and fer the like fantint of the boand no lear. the finest browncentiche bland to sup in the eyes, and was worked the time in the work. the travel of soul toly, lone to love thanly were ginatr him and linder to swoffiey so for no room entered wishe was conning of eyes steren of the unier of soul he finest to was never love to him, he love that was no so smelong in the were coul of his poweat. but thiss was coped hue finer. and moke gommenpesing so make oped in his work life wout him and ele and dead of ruther than the love that he finest so faind would nome of soul o getim the servoate spickent of coull classion nadartie corlige classing thater move to love a e a sconed ruther condithly and edge of soul toss was poacce, posis eyes and no speak no oped him of ent,ile own live coil of sister moke instarve sidered no speak of peeced and ant so far worll geteals the likis i was elives of the eyes, wis so far was he feigncides, just moviimmojuy power. so faicus eyes and she was judtimetape was to learg and as to he a man and so far wimnter was neak atere with of the cool gokestarry vaust ruted by in the was entitled to him, a the finest corloknowe to him and student and scove that was love toll and worke caby ine of the curberien oppositoct, and was a nurryes eyeake no love thant was eleving ideas now. thos towerang as him and starry vautuse vision of so farried, fll thing in the work. a fegttyventyvom in woy confing and fore the love that him ned ruth. he was never he so far wim with any of the cool to love a befe to the was no spirien so fa\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.LSTM at 0x14ce325bf60>"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM(Dataset(\"data/novel.txt\", substr_size=15)).train().generate(size=2500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:darkblue\">As we can tell form the output above, the results are already much better than wikipedia articles. It doesn't quite tell a story, nor even always output real words, but the overall structure is respected. In order to improve the results, maybe we can try working on <b>set of words</b> instead of a set of characters.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:darkblue\"><ul><li><b>Rap lyrics (cult Eminem songs' lyrics)</b></li></ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "253280/253280 [==============================] - 169s - loss: 1.7845   \n",
      "Epoch 2/5\n",
      "253280/253280 [==============================] - 132s - loss: 1.3066   \n",
      "Epoch 3/5\n",
      "253280/253280 [==============================] - 135s - loss: 1.1474   \n",
      "Epoch 4/5\n",
      "253280/253280 [==============================] - 132s - loss: 1.0631   \n",
      "Epoch 5/5\n",
      "253280/253280 [==============================] - 134s - loss: 1.0045   \n",
      "\n",
      "Generated from the seed \"that is gaping \":\n",
      "that is gaping too it with your cannin' yo be the be how why wigh like yo, in want to seour just lost it i'm job for with the with my han to examain than to stain to i cannto tan' to start it, i don't warn to be the beside, who lose-mout lick to, shit we acaust so i ain' to kneed to sk it that with the soldiers up in hance to know it the s in it i ain't way to words with my sincle bit by yid i hash't to so empty withougn to be the be h wert enfuct they s bizin' i hond to blow mhine to stop my foriers us an en with my cold orf my who wies i aildin l did in think off i'm stronnword it so me friettr no i an jaws, waysed with your jawsf never will, fuc wint! go too like you've be ho literort an to pert with him say with my like for my with than! popposuire 'caldm the grude to go to stom und than any shick i soldiers live 'em if some volf off, i reth to as an thet tat try to forge an exatow to forget yo you so i ail jost show in it to esed ain't the a littly 'cause wh in trom with now it even tho ways i say i'm just inht i had a like my ene'f you an the stent that i rent it i'm step by so futtard sti horied thin any sted to stop dors got to know hould eve works it i ain't not to st your jaws, way so i bettin' hoan the ust in to fet my likery bum murderection? it to winly get it to let me so forgured fuis the a conts trom in i'm i'm stiof it i ain' we acaum in fround even it, you anot my who's i'm just up in the so i cannto get be ho wart to sk it i ain't my whole up wi crosnels so i causs juct is to start it, to figul ust wilk my your i wants to stain' the man i'm stemout don't wann it i an my steppin' your you 'am t the hay we know how have none to as the front i way m what you kne somethor some cortronna fy us es off lted your see your my hand to a i canny, just inholf in so that you aways tho show how i feel like to ad i think i'm not to stop back i and ever win busy and to have i a not to get win may some so i ain lour to a start a rhyme i'm back it's your to just froing to be the be h then yo get so i ain forg so i an it, your nonit than to start he you 't niver without to eart anyshe face you've comply i wr chroan no, juct to i as so i went the shit we acat i were lost it to cross, it's no bention some on ef to stain to mind in to have now ords with the s the i have it boow i'm stamplina to forget it i ann that with the some on you think i'm jaws littly trat i say tot i had a lift is bits willin' to start an jobt, i'll like to domn withoud honest my witho\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.LSTM at 0x14ce9037ef0>"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM(Dataset(\"data/rap.txt\", substr_size=15)).train().generate(size=2500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:darkblue\">As we can tell from the output above, the results are quite encouraging, and even really funny as long you've got some imagination: <i>\"so i went the shit we acat i were lost it to cross,\", \"so i ain lour to a start a rhyme i'm back\", \"try to forge an exatow to forget yo you so i ail jost show in it\", \"your jawsf never will, fuc wint!\"</i>. This model obviously isn't ready to write some real rap lyrics, but it definitely shows that there are a lot of things we can do in this domain.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with other methods: N-grams\n",
    "<br>\n",
    "<div style=\"color:darkblue\">Instead of using a complex method like the LSTMs, we're going to use a very simple statistical method based on n-grams and compare the results.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "\n",
    "# Set some global constants\n",
    "LANGUAGES = {'eng': 'english', 'frn': 'french'} # Languages to load \n",
    "DATA_PATH = os.path.join(os.getcwd(), './data/') # Where to find the Kaggle Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loads a text corpus\n",
    "def load_txt(path):\n",
    "    with open(path, 'r') as file:\n",
    "        return file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper to remove chars that will not be correctly encoded\n",
    "def remove_unknown(text):\n",
    "    return re.sub(r'[^(a-z)+\\d+ \\.,;\"\\'\\?!\\-_:)]', '', re.sub(r'[\\n\\t]', ' ', text.lower())).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_language_corpuses(languages=LANGUAGES, path=DATA_PATH):\n",
    "    corpuses = {}\n",
    "    for langid, lang in languages.items():\n",
    "        corpuses[lang] = remove_unknown(load_txt(os.path.join(path, langid + '.txt')))\n",
    "    return corpuses\n",
    "\n",
    "corpuses = load_language_corpuses()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:darkblue\">The main part of this is to generate a bunch of bigrams and trigrams from the training data.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_ngrams(text, nrange=[2, 3]):\n",
    "    ng = []\n",
    "    for n in nrange:\n",
    "        ng += ngrams(text, n)\n",
    "    return ng\n",
    "\n",
    "def split_text(text, test_split=.2):\n",
    "    train_len = int(len(text)*(1-test_split))\n",
    "    return text[:train_len], text[train_len:]\n",
    "\n",
    "def gen_ngrams_for_corpus(corpuses, nrange=[2, 3], test_split=.2):\n",
    "    train_grams = {}\n",
    "    test_grams = {}\n",
    "    for lang, text in corpuses.items():\n",
    "        tr, te = split_text(text, test_split)\n",
    "        train_grams[lang] = gen_ngrams(tr, nrange)\n",
    "        test_grams[lang] = gen_ngrams(te, nrange)\n",
    "    return train_grams, test_grams\n",
    "\n",
    "corpuses_train_grams, corpuses_test_grams = gen_ngrams_for_corpus(corpuses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:darkblue\">Then, we just count how many times they actually appear.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_ngram_freqs(ngrams):\n",
    "    apparitions = {}\n",
    "    tot_app = len(ngrams)\n",
    "    for ngram in ngrams:\n",
    "        if ngram in apparitions:\n",
    "            apparitions[ngram] += 1\n",
    "        else:\n",
    "            apparitions[ngram] = 1\n",
    "    ng_freq = {}\n",
    "    for ng, app in apparitions.items():\n",
    "        ng_freq[ng] = float(app)/float(tot_app)\n",
    "    return ng_freq\n",
    "\n",
    "ngram_freq_en = gen_ngram_freqs(corpuses_train_grams['english'])\n",
    "ngram_freq_fr = gen_ngram_freqs(corpuses_train_grams['french'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:darkblue\">Finally, we can score some test bigrams and trigrams by just looking up the frequencies.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.738775985558583"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def score_ng(ngram_freqs, ngrams_test):\n",
    "    score = 0\n",
    "    for gram in ngrams_test:\n",
    "        if gram in ngram_freqs:\n",
    "            score += ngram_freqs[gram]\n",
    "    return score\n",
    "\n",
    "score_ng(ngram_freq_en, corpuses_test_grams['english'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:darkblue\">By comparing the score for each model, we can make prediction and therefore get the accuracy.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7491204925241864"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ng_accuracy(freq_lang1, freq_lang2, test_lang1, test_lang2, substr=5, nrange=[2,3]):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i in range(len(test_lang1)):\n",
    "        text = test_lang1[i:i+substr]\n",
    "        grams = gen_ngrams(text, nrange)\n",
    "        total += 1\n",
    "        if score_ng(freq_lang1, grams) > score_ng(freq_lang2, grams):\n",
    "            correct += 1\n",
    "    for i in range(len(test_lang2)):\n",
    "        text = test_lang2[i:i+substr]\n",
    "        grams = gen_ngrams(text, nrange)\n",
    "        total += 1\n",
    "        if score_ng(freq_lang2, grams) > score_ng(freq_lang1, grams):\n",
    "            correct += 1\n",
    "    return float(correct)/float(total)\n",
    "\n",
    "_, en_test_text = split_text(corpuses['english'])\n",
    "_, fr_test_text = split_text(corpuses['french'])\n",
    "\n",
    "ng_accuracy(ngram_freq_en, ngram_freq_fr, en_test_text, fr_test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:darkblue\">Given the simplicity of the model, the results are fairly good. But once tuned, the LSTMs have proven themselves to be capable of much higher scores.</div>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:DeepLearning]",
   "language": "python",
   "name": "conda-env-DeepLearning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
